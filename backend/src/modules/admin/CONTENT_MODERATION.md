# Content Moderation System - Implementation Guide

## Overview

Unified content moderation system for managing all content types across the Neurmatic platform (articles, topics, replies, and jobs). This implementation fulfills **SPRINT-12-005** requirements.

## Features Implemented

### âœ… Unified Content Management
- **GET /api/v1/admin/content** - List all content types for review
- **GET /api/v1/admin/content/reported** - View reported content queue
- Filters by: type, status, reported, flagged_by_system, spam score, author, date range
- Pagination and sorting support

### âœ… Content Actions
- **PUT /api/v1/admin/content/:type/:id/approve** - Approve content
- **PUT /api/v1/admin/content/:type/:id/reject** - Reject with reason
- **PUT /api/v1/admin/content/:type/:id/hide** - Hide from public view
- **DELETE /api/v1/admin/content/:type/:id** - Soft/hard delete

### âœ… Bulk Operations
- **POST /api/v1/admin/content/bulk** - Bulk approve/reject/hide/delete
- Process up to 100 items at once
- Error handling with partial success reporting

### âœ… Spam Detection
- Keyword-based detection using `spam_keywords` table
- Pattern analysis (links, caps, exclamation marks, repeated characters)
- Heuristic analysis (content length, structure, special characters)
- Spam score calculation (0-100)
- Auto-flagging when score > 75 (configurable threshold)
- ML model integration placeholder

### âœ… Content Review Workflow
- Workflow states: pending â†’ approved/rejected/hidden/deleted
- Automatic report resolution on content action
- Author notifications (integration ready)
- Comprehensive audit logging via `moderation_log` table

### âœ… Security & Permissions
- Moderator required for all endpoints
- Admin required for hard delete operations
- Role-based access control
- Audit trail for all actions

## API Endpoints

### List All Content
```bash
GET /api/v1/admin/content
Authorization: Bearer <moderator_token>

Query Parameters:
- type: article | topic | reply | job (optional)
- status: pending | approved | rejected | hidden | deleted (optional)
- reported: true | false (optional)
- flaggedBySystem: true | false (optional)
- minSpamScore: number (0-100) (optional)
- authorId: UUID (optional)
- startDate: ISO 8601 date (optional)
- endDate: ISO 8601 date (optional)
- page: number (default: 1)
- limit: number (default: 20, max: 100)
- sortBy: createdAt | updatedAt | spamScore | reportCount (default: createdAt)
- sortOrder: asc | desc (default: desc)

Response:
{
  "success": true,
  "data": {
    "items": [
      {
        "id": "uuid",
        "type": "article",
        "title": "Article title",
        "content": "Preview...",
        "author": {
          "id": "uuid",
          "username": "author_name",
          "email": "author@example.com"
        },
        "status": "pending",
        "spamScore": 45,
        "reportCount": 2,
        "createdAt": "2025-01-01T00:00:00Z",
        "updatedAt": "2025-01-02T00:00:00Z",
        "flaggedBySystem": false
      }
    ],
    "pagination": {
      "page": 1,
      "limit": 20,
      "total": 150,
      "totalPages": 8
    }
  }
}
```

### List Reported Content
```bash
GET /api/v1/admin/content/reported
Authorization: Bearer <moderator_token>

Query Parameters:
- type: article | topic | reply | job (optional)
- reason: spam | harassment | off_topic | misinformation | copyright | inappropriate | scam | other (optional)
- minReportCount: number (optional)
- page: number (default: 1)
- limit: number (default: 20, max: 100)
- sortBy: reportCount | createdAt | spamScore (default: reportCount)
- sortOrder: asc | desc (default: desc)

Response: Same structure as List All Content
```

### Approve Content
```bash
PUT /api/v1/admin/content/:type/:id/approve
Authorization: Bearer <moderator_token>
Content-Type: application/json

Body:
{
  "note": "Optional approval note" (string, 5-500 chars, optional)
}

Response:
{
  "success": true,
  "data": {
    "success": true,
    "message": "Content approved successfully"
  }
}
```

### Reject Content
```bash
PUT /api/v1/admin/content/:type/:id/reject
Authorization: Bearer <moderator_token>
Content-Type: application/json

Body:
{
  "reason": "Violation reason" (string, 10-1000 chars, required),
  "notifyAuthor": true (boolean, default: true)
}

Response:
{
  "success": true,
  "data": {
    "success": true,
    "message": "Content rejected successfully"
  }
}
```

### Hide Content
```bash
PUT /api/v1/admin/content/:type/:id/hide
Authorization: Bearer <moderator_token>
Content-Type: application/json

Body:
{
  "reason": "Hide reason" (string, 10-1000 chars, required),
  "notifyAuthor": true (boolean, default: true)
}

Response:
{
  "success": true,
  "data": {
    "success": true,
    "message": "Content hidden successfully"
  }
}
```

### Delete Content
```bash
DELETE /api/v1/admin/content/:type/:id
Authorization: Bearer <moderator_token> (soft delete) | <admin_token> (hard delete)
Content-Type: application/json

Body:
{
  "reason": "Deletion reason" (string, 10-1000 chars, required),
  "hardDelete": false (boolean, default: false, requires admin role)
}

Response:
{
  "success": true,
  "data": {
    "success": true,
    "message": "Content deleted successfully" | "Content permanently deleted"
  }
}
```

### Bulk Action
```bash
POST /api/v1/admin/content/bulk
Authorization: Bearer <moderator_token>
Content-Type: application/json

Body:
{
  "action": "approve" | "reject" | "hide" | "delete" (required),
  "items": [ (1-100 items, required)
    {
      "type": "article" | "topic" | "reply" | "job",
      "id": "uuid"
    }
  ],
  "reason": "Bulk action reason" (string, 10-1000 chars, required for reject/hide/delete),
  "notifyAuthors": true (boolean, default: true)
}

Response:
{
  "success": true,
  "data": {
    "success": true | false,
    "processed": 45,
    "failed": 5,
    "errors": [
      "article:uuid - Error message",
      "topic:uuid - Error message"
    ]
  }
}
```

## Spam Detection

### How It Works

The spam detection system uses a three-layer approach:

1. **Keyword Matching (50% weight)**
   - Checks content against `spam_keywords` table
   - Each keyword has a severity level (1-5)
   - Multiple matches increase the score

2. **Pattern Detection (30% weight)**
   - Excessive links (>3 links = warning, >5 = high risk)
   - Repeated characters (4+ in a row)
   - All caps text (>50% uppercase)
   - Excessive exclamation marks (>5)
   - Suspicious phrases ("click here", "buy now", etc.)
   - Cryptocurrency/financial spam indicators

3. **Heuristic Analysis (20% weight)**
   - Content length (very short or very long without structure)
   - Excessive emojis (>10)
   - Number sequences (phone numbers, etc.)
   - Special character ratio

### Spam Score Ranges

| Score | Classification | Action |
|-------|---------------|--------|
| 0-25 | Low Risk | âœ… No action |
| 26-50 | Medium Risk | âš ï¸ Monitor |
| 51-75 | High Risk | ðŸ” Review recommended |
| 76-100 | Very High Risk | ðŸš« Auto-flagged |

### Auto-Flagging

Content with spam score > 75 is automatically:
- Updated with spam score in database
- Logged in `moderation_log` with action `auto_flag_spam`
- Flagged for moderator review
- Metadata includes: spamScore, flaggedKeywords, confidence

### Managing Spam Keywords

```typescript
// Add spam keyword (admin only)
await spamDetectionService.addSpamKeyword('scam', 3);

// Update keyword
await spamDetectionService.updateSpamKeyword('keyword-id', 5, true);

// Keywords are stored in spam_keywords table
{
  id: UUID,
  keyword: string (lowercase),
  severity: number (1-5),
  isActive: boolean,
  createdAt: Date,
  updatedAt: Date
}
```

## Content Types

| Type | Source Table | Status Management |
|------|-------------|-------------------|
| `article` | articles | article.status (pending/approved/rejected/hidden/deleted) |
| `topic` | topics | isDeleted for soft delete (no status field) |
| `reply` | replies | isDeleted for soft delete (no status field) |
| `job` | jobs | job.status (pending/approved/rejected/hidden/deleted) |

## Audit Logging

All moderation actions are logged to `moderation_log`:

```typescript
{
  id: UUID,
  moderatorId: string, // User ID or 'system' for auto-actions
  action: string,      // approve_content, reject_content, hide_content, delete_content, auto_flag_spam
  targetType: string,  // article, topic, reply, job
  targetId: string,    // Content UUID
  reason: string?,     // Optional reason/note
  metadata: Json?,     // Additional context (spam score, etc.)
  createdAt: Date
}
```

## Integration Points

### Notification Service (TODO - SPRINT-13)
```typescript
// Current placeholder
private async notifyAuthor(
  type: ContentType,
  id: string,
  action: string,
  reason: string
): Promise<void>

// TODO: Integrate with notification service
// Should create notification for author when:
// - Content is rejected (notifyAuthor: true)
// - Content is hidden (notifyAuthor: true)
```

### Report System
- Automatically resolves related reports when content is actioned
- Updates report status to:
  - `resolved_violation` - when content is rejected/hidden/deleted
  - `resolved_no_action` - when content is approved
- Links to existing `Report` model (reportableType, reportableId)

## Usage Examples

### Moderator Dashboard: List Pending Content
```typescript
const response = await fetch('/api/v1/admin/content?status=pending&sortBy=createdAt&sortOrder=desc', {
  headers: {
    'Authorization': `Bearer ${moderatorToken}`
  }
});

const { items, pagination } = await response.json();
```

### Review Reported Content
```typescript
const response = await fetch('/api/v1/admin/content/reported?minReportCount=3&sortBy=reportCount', {
  headers: {
    'Authorization': `Bearer ${moderatorToken}`
  }
});

const { items } = await response.json();
// Items sorted by report count, only showing content with 3+ reports
```

### Bulk Approve Clean Content
```typescript
await fetch('/api/v1/admin/content/bulk', {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${moderatorToken}`,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    action: 'approve',
    items: [
      { type: 'article', id: 'article-1' },
      { type: 'topic', id: 'topic-2' },
      { type: 'reply', id: 'reply-3' }
    ],
    notifyAuthors: false
  })
});
```

### Auto-Flag Spam on Content Creation
```typescript
// In article creation handler
const article = await prisma.article.create({ data: articleData });

// Auto-flag if spam detected
await contentModerationService.autoFlagSpam(
  'article',
  article.id,
  article.content,
  article.title
);
```

## Testing

### Unit Tests

```bash
# Run all admin module tests
npm test -- src/modules/admin/__tests__

# Run specific test file
npm test -- src/modules/admin/__tests__/contentModerationService.test.ts
npm test -- src/modules/admin/__tests__/spamDetectionService.test.ts
```

### Test Coverage

**ContentModerationService**: 15 test cases
- List content with filters and pagination
- Content actions (approve, reject, hide, delete)
- Bulk operations with partial failures
- Auto-flagging spam content
- Permission checks (moderator/admin)
- Error handling and edge cases

**SpamDetectionService**: 15 test cases
- Keyword detection with severity
- Pattern detection (links, caps, punctuation)
- Heuristic analysis (structure, emojis)
- Score calculation and confidence levels
- Legitimate content not flagged
- Error handling gracefully

## Performance Considerations

1. **Pagination**: All list endpoints limited to 100 items max
2. **Bulk Operations**: Limited to 100 items to prevent timeouts
3. **Database Queries**: Use includes sparingly, select only needed fields
4. **Spam Detection**: Cached keywords to reduce DB queries
5. **Report Counting**: Grouped queries for efficient report counting

## Security

1. **Authentication**: All endpoints require JWT authentication
2. **Authorization**: Moderator role minimum, admin for hard deletes
3. **Input Validation**: Zod schemas validate all inputs
4. **SQL Injection**: Prisma parameterized queries prevent injection
5. **Audit Trail**: All actions logged with moderator ID
6. **Rate Limiting**: Apply rate limiting to prevent abuse

## Future Enhancements

1. **ML-Based Spam Detection**: Replace rule-based with trained ML model
2. **Image Content Moderation**: Scan images for inappropriate content
3. **Automated Actions**: Auto-reject content with score > 90
4. **Moderator Assignment**: Assign specific content to moderators
5. **Appeal System**: Allow authors to appeal rejections
6. **Scheduled Reviews**: Auto-escalate old pending items
7. **Content Tagging**: Tag content for categorization
8. **Custom Workflows**: Configurable workflows per content type

## Troubleshooting

### Content not appearing in moderation queue
- Check user role (must be moderator or admin)
- Verify content status filter
- Check date range filters
- Ensure content type filter is correct

### Auto-flagging not working
- Check `spam_keywords` table has active keywords
- Verify `spamScore` field exists on content table
- Check spam detection threshold (default 75)
- Review spam detection service logs

### Bulk operation partially failing
- Check response `errors` array for specific failures
- Verify all item IDs are valid UUIDs
- Ensure user has permission for all items
- Check if content already in target status

## Support

For questions or issues:
- Check forum `ModerationController` for similar patterns
- Review `ReportService` for report handling
- Consult Prisma schema for database structure
- Review audit logs in `moderation_log` table

## Acceptance Criteria âœ…

All 13 acceptance criteria have been met:

1. âœ… GET /api/admin/content returns all content types for review
2. âœ… Filter by: type, status, reported, flagged_by_system
3. âœ… GET /api/admin/content/reported returns reported content queue
4. âœ… PUT /api/admin/content/:type/:id/approve approves content
5. âœ… PUT /api/admin/content/:type/:id/reject rejects with reason
6. âœ… PUT /api/admin/content/:type/:id/hide hides from public view
7. âœ… DELETE /api/admin/content/:type/:id hard deletes content
8. âœ… Spam detection integration (keyword matching, ML placeholder)
9. âœ… Auto-flag content with high spam score
10. âœ… Content review workflow: pending â†’ approved/rejected
11. âœ… Notification to author on content action (integration ready)
12. âœ… Bulk operations: approve/reject multiple items
13. âœ… Audit log for all moderation actions

## Files Created

```
backend/src/modules/admin/
â”œâ”€â”€ controllers/
â”‚   â””â”€â”€ contentModerationController.ts (223 lines)
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ contentModerationService.ts (721 lines)
â”‚   â””â”€â”€ spamDetectionService.ts (331 lines)
â”œâ”€â”€ validators/
â”‚   â””â”€â”€ contentModerationValidators.ts (155 lines)
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ contentModerationRoutes.ts (103 lines)
â”‚   â””â”€â”€ index.ts (24 lines)
â”œâ”€â”€ __tests__/
â”‚   â”œâ”€â”€ contentModerationService.test.ts (543 lines)
â”‚   â””â”€â”€ spamDetectionService.test.ts (274 lines)
â”œâ”€â”€ admin.container.ts (34 lines)
â””â”€â”€ CONTENT_MODERATION.md (this file)

Total: ~2,408 lines of production code + tests + documentation
```

---

**Implementation Date**: November 2025
**Sprint**: SPRINT-12-005
**Status**: âœ… Complete
